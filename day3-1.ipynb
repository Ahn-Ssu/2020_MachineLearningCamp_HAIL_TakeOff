{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"day3-1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"20zg4nCJO4Ay","colab_type":"text"},"source":["#5. Scikit-Learn (`sklearn`)\n","\n","오늘은 Scikit-Learn (sklearn) 패키지를 사용하여 모델 학습과 테스트를 진행합니다."]},{"cell_type":"markdown","metadata":{"id":"owXNVT3gCzh4","colab_type":"text"},"source":["##5.1. Random Forest - Ensemble of Decision Trees\n","\n","먼저 필요한 라이브러리들을 불러옵니다. 오늘 사용할 라이브러리들이 다음의 code snippet에 기술되어 있습니다.\n","\n","Scikit-Learn (sklearn) 패키지에는 ML 공부를 할 때 자주 사용되는 데이터셋들도 포함이 되어 있습니다. 그러한 데이터셋 중 Iris라는 데이터셋을 사용해보겠습니다. 이는 iris 꽃잎의 체적에 관한 정보에 근거하여 꽃의 품종을 결정하고자하는 데이터셋입니다.\n","\n","> Attribute Information:\n","> 1. sepal length in cm \n","> 2. sepal width in cm \n","> 3. petal length in cm \n","> 4. petal width in cm \n","> 5. class: {Setosa, Versicolour, Virginica}\n","\n","<img src=\"https://d31ezp3r8jwmks.cloudfront.net/variants/2dzeX71EceP88fenXxy1uj1t/d2e337a4f6900f8d0798c596eb0607a8e0c2fbddb6a7ab7afcd60009c119d4c7\" width=\"500\">\n","\n","\n","<img src=\"https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Machine+Learning+R/iris-machinelearning.png\" width=\"500\">\n","\n"]},{"cell_type":"code","metadata":{"id":"QqZ4AGG0Ld89","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1594144636361,"user_tz":-540,"elapsed":1607,"user":{"displayName":"Charmgil Hong","photoUrl":"","userId":"00848486677788331656"}},"outputId":"034efca7-ef6f-41c8-ab6d-0b6097174949"},"source":["# Import libraries\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import GridSearchCV\n","#from sklearn.model_selection import cross_validate\n","import warnings\n","warnings.simplefilter(action='ignore', category=FutureWarning)\n","warnings.simplefilter(action='ignore', category=DeprecationWarning)\n","\n","\n","# Classification metrics\n","from sklearn.metrics import (accuracy_score, precision_score, \n","                             recall_score, f1_score, log_loss)\n","\n","# Load the Iris dataset\n","from sklearn.datasets import load_iris\n","X, y = load_iris(return_X_y=True)\n","\n","list(zip(X[:5],y[:5])) # show first 5 instances\n"],"execution_count":1,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[(array([5.1, 3.5, 1.4, 0.2]), 0),\n"," (array([4.9, 3. , 1.4, 0.2]), 0),\n"," (array([4.7, 3.2, 1.3, 0.2]), 0),\n"," (array([4.6, 3.1, 1.5, 0.2]), 0),\n"," (array([5. , 3.6, 1.4, 0.2]), 0)]"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"markdown","metadata":{"id":"IKOBR6stIS2h","colab_type":"text"},"source":["이제 수업을 통해 이야기 나눈 절차에 따라 sklearn을 사용해보겠습니다.\n","\n","#### Step 1 - Separating training and testing datasets\n","첫 단계로 학습된 모델의 정확한 검증을 위해 데이터셋을 training set과 testing set으로 분리를 합니다."]},{"cell_type":"code","metadata":{"id":"WdtSGZO4C2RG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1594144636362,"user_tz":-540,"elapsed":1600,"user":{"displayName":"Charmgil Hong","photoUrl":"","userId":"00848486677788331656"}}},"source":["X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.4, random_state=777)"],"execution_count":2,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XjswJdabJMMz","colab_type":"text"},"source":["#### Steps 2 & 3 - Optimize hyperparameters via cross validation\n","먼저 시도해볼 모델은 Random Forest 입니다. `GridSearchCV`를 사용하여 학습에 사용될 hyperparameters를 찾습니다. `GridSearchCV`의 `fit()` 함수를 사용하면, Hyperparameter 탐색과 학습 과정이 모두 수행됩니다. 다음 code snippet을 수행하고 나면, `best_clf`에 최종적으로 학습된 모델이 저장됩니다."]},{"cell_type":"code","metadata":{"id":"rd0jvpNcJMiz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":170},"executionInfo":{"status":"ok","timestamp":1594144641998,"user_tz":-540,"elapsed":7229,"user":{"displayName":"Charmgil Hong","photoUrl":"","userId":"00848486677788331656"}},"outputId":"59d41ae6-a0ff-4022-ff12-e39306e9a280"},"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","# Instantiate a model object\n","clf = RandomForestClassifier()\n","\n","# Set a serach range\n","parameters = {'n_estimators': [100, 150, 200],\n","              'criterion': ['gini', 'entropy']}\n","# Find the best hyperparameters using GridSearchCV\n","gridsearch = GridSearchCV(clf, parameters, scoring='accuracy', cv=5)\n","gridsearch.fit(X_tr, y_tr)\n","\n","# Show the best hyperparameters\n","# String starts with 'f' - print out a floating point number in the string\n","\n","print(f'gridsearch.best_params_ = {gridsearch.best_params_}') \n","\n","# The best model is stored in 'best_clf'\n","best_clf = gridsearch.best_estimator_\n","best_clf"],"execution_count":3,"outputs":[{"output_type":"stream","text":["gridsearch.best_params_ = {'criterion': 'gini', 'n_estimators': 100}\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=100,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"markdown","metadata":{"id":"UlUc2K4yJ81q","colab_type":"text"},"source":["####Step 4 - Model performance\n","얻어진 모델을 앞서 떼어두었던 테스트 데이터셋에 적용해봅니다. `predict()` 함수를 통해 예측이 이루어지며, `accuracy_score()` 함수를 사용하면 쉽게 정확도를 계산해볼 수 있습니다.\n"]},{"cell_type":"code","metadata":{"id":"DoNu8-6RLvHt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1594144641999,"user_tz":-540,"elapsed":7221,"user":{"displayName":"Charmgil Hong","photoUrl":"","userId":"00848486677788331656"}},"outputId":"3a3f3ed1-e128-48f9-f144-0263972471a5"},"source":["y_pred = best_clf.predict(X_ts)\n","test_acc = accuracy_score(y_ts, y_pred)\n","print(f'test_acc = {test_acc}')\n"],"execution_count":4,"outputs":[{"output_type":"stream","text":["test_acc = 0.9333333333333333\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2Ap0ZZllM5hN","colab_type":"text"},"source":["####Step 5 - Train final model on full dataset (optional step)\n","선택적으로 train data와 test data를 모두 고려하여, 최종 배포용 모델을 다시 학습할 수 있습니다. 이 때, 앞서 탐색을 통해 찾은 hyperparameters를 다시 사용하면 됩니다."]},{"cell_type":"code","metadata":{"id":"QUflJnERM5vy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1594144642000,"user_tz":-540,"elapsed":7214,"user":{"displayName":"Charmgil Hong","photoUrl":"","userId":"00848486677788331656"}},"outputId":"e6626fbe-c605-4bce-900e-149154265f94"},"source":["final_model = RandomForestClassifier(**gridsearch.best_params_)\n","final_model.fit(X, y)\n"],"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n","                       criterion='gini', max_depth=None, max_features='auto',\n","                       max_leaf_nodes=None, max_samples=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=100,\n","                       n_jobs=None, oob_score=False, random_state=None,\n","                       verbose=0, warm_start=False)"]},"metadata":{"tags":[]},"execution_count":5}]},{"cell_type":"markdown","metadata":{"id":"y-8HO2cMA752","colab_type":"text"},"source":["##5.2. Logistic Regression (LogReg)\n","\n","이번 절에서는 Scikit-Learn (sklearn)에 포함되어있는 logistic regression 모듈을 사용하여, iris 데이터셋 학습을 진행해보겠습니다.\n","\n","Logisitc regression을 사용할 때, input features는 모두 같은 scale을 갖도록 해주어야 합니다. `sklearn.preprocessing.MinMaxScaler`를 사용하면, 손쉽게 normalization을 진행할 수 있습니다."]},{"cell_type":"code","metadata":{"id":"B_C6u4ZOA6d1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1594144642000,"user_tz":-540,"elapsed":7206,"user":{"displayName":"Charmgil Hong","photoUrl":"","userId":"00848486677788331656"}},"outputId":"ee42d9f0-29e5-43a7-dda4-66c8ab4a439e"},"source":["from sklearn.linear_model import LogisticRegression\n","from sklearn.preprocessing import MinMaxScaler\n","\n","# (Re-)Load a dataset\n","X, y = load_iris(return_X_y=True)\n","\n","# Step 1: Get training and testing datasets\n","X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.4, random_state=777)\n","\n","# Data normalization\n","normalizer = MinMaxScaler(feature_range=(0, 1))\n","normalizer.fit(X_tr)\n","X_tr_normalized = normalizer.transform(X_tr)\n","X_ts_normalized = normalizer.transform(X_ts)\n","\n","# Show first 5 instances\n","print('Before normalization:\\n', X_tr[:5])\n","print('After normalization:\\n', X_tr_normalized[:5])"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Before normalization:\n"," [[5.5 2.4 3.7 1. ]\n"," [6.3 2.8 5.1 1.5]\n"," [4.6 3.1 1.5 0.2]\n"," [4.8 3.1 1.6 0.2]\n"," [4.5 2.3 1.3 0.3]]\n","After normalization:\n"," [[0.34375    0.16666667 0.46296296 0.375     ]\n"," [0.59375    0.33333333 0.72222222 0.58333333]\n"," [0.0625     0.45833333 0.05555556 0.04166667]\n"," [0.125      0.45833333 0.07407407 0.04166667]\n"," [0.03125    0.125      0.01851852 0.08333333]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DEBhZ6o-ALs6","colab_type":"text"},"source":["이제 학습과 테스트를 진행해봅니다."]},{"cell_type":"code","metadata":{"id":"_ef67yr5AQRG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594144642789,"user_tz":-540,"elapsed":7987,"user":{"displayName":"Charmgil Hong","photoUrl":"","userId":"00848486677788331656"}},"outputId":"3be4d325-27d4-496d-cc6e-2ecc7ca83bbc"},"source":["# Step 2: Use GridSearchCV to find optimal hyperparameter values\n","clf = LogisticRegression(max_iter=5000)\n","parameters = {'penalty': ['l2'],\n","              'C': [10e-5, 10e-3, 10e-2, 10e-1, 10e0, 10e1, 10e2, 10e3, 10e5]}\n","gridsearch = GridSearchCV(clf, parameters, scoring='accuracy', cv=5)\n","gridsearch.fit(X_tr_normalized, y_tr)\n","print(f'gridsearch.best_params_ = {gridsearch.best_params_}')\n","\n","# Step 3: Get model with best hyperparameters\n","best_clf = gridsearch.best_estimator_\n","\n","# Step 4: Get best model performance from testing set\n","y_pred = best_clf.predict(X_ts_normalized)\n","test_acc = accuracy_score(y_ts, y_pred)\n","print(f'test_acc = {test_acc}')\n"],"execution_count":7,"outputs":[{"output_type":"stream","text":["gridsearch.best_params_ = {'C': 100.0, 'penalty': 'l2'}\n","test_acc = 0.9833333333333333\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"ut67frDsRTaq","colab_type":"text"},"source":["##5.3. Benchmark\n","이번 절에서는 조금 복잡한 데이터셋을 생성하여 random forest와 logistic regression 모델에 각각 적용해보고, 예측 결과를 비교해보고자 합니다. 우리는 sklearn에 내장된 모듈을 사용하여 non-linear decision boundary를 갖는 데이터셋을 생성해보고, 이 데이터셋에 대하여 각 모델의 예측 정확도가 어떻게 되는지 비교해보고자 합니다."]},{"cell_type":"markdown","metadata":{"id":"CQfpW-XDRn2N","colab_type":"text"},"source":["####Dataset\n","\n","`make_circles` 모듈을 사용하여 1,000개의 data instances를 생성합니다. 이어지는 코드는 `matplotlib`으로 생성된 데이터셋을 시각화하여 줍니다."]},{"cell_type":"code","metadata":{"id":"wgQeLxlrRnMp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":196},"executionInfo":{"status":"ok","timestamp":1594144642790,"user_tz":-540,"elapsed":7979,"user":{"displayName":"Charmgil Hong","photoUrl":"","userId":"00848486677788331656"}},"outputId":"ada15216-88d4-4ae9-cc99-dc90c8d798ff"},"source":["from sklearn.datasets import make_circles\n","import matplotlib.pyplot as plt\n","\n","# Generate a dataset\n","X, y = make_circles(n_samples=1000, factor=.3, noise=.05)\n","\n","# Show the dataset\n","plt.figure()\n","plt.subplot(2, 2, 1, aspect='equal')\n","plt.title(\"Generated dataset\")\n","reds = y == 0\n","blues = y == 1\n","\n","plt.scatter(X[reds, 0], X[reds, 1], c=\"red\", s=20, edgecolor='k')\n","plt.scatter(X[blues, 0], X[blues, 1], c=\"blue\", s=20, edgecolor='k')\n","plt.xlabel(\"$x_1$\")\n","plt.ylabel(\"$x_2$\")\n"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0, 0.5, '$x_2$')"]},"metadata":{"tags":[]},"execution_count":8},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"markdown","metadata":{"id":"sLzrLYPzRcKZ","colab_type":"text"},"source":["#### LogReg\n","\n","먼저 logistic regression을 적용해봅니다. 위에서와 동일한 구조의 코드를 사용합니다."]},{"cell_type":"code","metadata":{"id":"yQPUjKnETTrq","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594144643040,"user_tz":-540,"elapsed":8222,"user":{"displayName":"Charmgil Hong","photoUrl":"","userId":"00848486677788331656"}},"outputId":"d0e0bdd8-15cb-41c3-a90c-c85bbd1655dc"},"source":["# Step 1: Get training and testing datasets\n","X_tr, X_ts, y_tr, y_ts = train_test_split(X, y, test_size=0.4, random_state=777)\n","\n","# Data normalization\n","normalizer = MinMaxScaler(feature_range=(0, 1))\n","normalizer.fit(X_tr)\n","X_tr_normalized = normalizer.transform(X_tr)\n","X_ts_normalized = normalizer.transform(X_ts)\n","\n","\n","# Step 2: Use GridSearchCV to find optimal hyperparameter values\n","clf = LogisticRegression(max_iter=5000)\n","parameters = {'penalty': ['l2'],\n","              'C': [10e-5, 10e-3, 10e-2, 10e-1, 10e0, 10e1, 10e2, 10e3, 10e5]}\n","gridsearch = GridSearchCV(clf, parameters, scoring='accuracy', cv=5)\n","gridsearch.fit(X_tr_normalized, y_tr)\n","print(f'gridsearch.best_params_ = {gridsearch.best_params_}')\n","\n","# Step 3: Get model with best hyperparameters\n","best_clf = gridsearch.best_estimator_\n","\n","# Step 4: Get best model performance from testing set\n","y_pred = best_clf.predict(X_ts_normalized)\n","test_acc = accuracy_score(y_ts, y_pred)\n","print(f'test_acc = {test_acc}')"],"execution_count":9,"outputs":[{"output_type":"stream","text":["gridsearch.best_params_ = {'C': 0.0001, 'penalty': 'l2'}\n","test_acc = 0.4825\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"f0lgd517ZNP4","colab_type":"text"},"source":["####DT\n","\n","이번엔 Sklearn을 사용한 decision tree입니다."]},{"cell_type":"code","metadata":{"id":"C4YFhr4TZOrj","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594144643041,"user_tz":-540,"elapsed":8215,"user":{"displayName":"Charmgil Hong","photoUrl":"","userId":"00848486677788331656"}},"outputId":"67430b9a-3af8-4971-f7ff-54911c52b293"},"source":["from sklearn.tree import DecisionTreeClassifier\n","\n","# Step 2: Use GridSearchCV to find optimal hyperparameter values\n","clf = DecisionTreeClassifier()\n","parameters = {'criterion': ['gini', 'entropy']}\n","gridsearch = GridSearchCV(clf, parameters, scoring='accuracy', cv=5)\n","gridsearch.fit(X_tr, y_tr)\n","print(f'gridsearch.best_params_ = {gridsearch.best_params_}')\n","\n","# Step 3: Get model with best hyperparameters\n","best_clf = gridsearch.best_estimator_\n","\n","# Step 4: Get best model performance from testing set\n","y_pred = best_clf.predict(X_ts)\n","test_acc = accuracy_score(y_ts, y_pred)\n","print(f'test_acc = {test_acc}')"],"execution_count":10,"outputs":[{"output_type":"stream","text":["gridsearch.best_params_ = {'criterion': 'gini'}\n","test_acc = 0.9925\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LEH5Km_wTP7o","colab_type":"text"},"source":["####RF\n","\n","마지막으로 Sklearn을 사용한 random forest입니다."]},{"cell_type":"code","metadata":{"id":"gW8u2M2RRZAE","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1594144651103,"user_tz":-540,"elapsed":16267,"user":{"displayName":"Charmgil Hong","photoUrl":"","userId":"00848486677788331656"}},"outputId":"898b09d0-36a4-4c11-c10d-751ea7a42b3f"},"source":["from sklearn.ensemble import RandomForestClassifier\n","\n","# Step 2: Use GridSearchCV to find optimal hyperparameter values\n","clf = RandomForestClassifier()\n","parameters = {'n_estimators': [50, 100, 150, 200],\n","              'criterion': ['gini', 'entropy']}\n","gridsearch = GridSearchCV(clf, parameters, scoring='accuracy', cv=5)\n","\n","gridsearch.fit(X_tr, y_tr)\n","print(f'gridsearch.best_params_ = {gridsearch.best_params_}')\n","\n","# Step 3: Get model with best hyperparameters\n","best_clf = gridsearch.best_estimator_\n","\n","# Step 4: Get best model performance from testing set\n","y_pred = best_clf.predict(X_ts)\n","test_acc = accuracy_score(y_ts, y_pred)\n","print(f'test_acc = {test_acc}')"],"execution_count":11,"outputs":[{"output_type":"stream","text":["gridsearch.best_params_ = {'criterion': 'gini', 'n_estimators': 50}\n","test_acc = 0.9925\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1JqJhR-_Ch9a","colab_type":"text"},"source":["**Q: 세 모델의 예측 성능이 각각 어떻게 나타나나요? 주어진 데이터셋에 대하여, logistic regression, decision tree, random forest 중 어떤 모델이 더 적합할까요? 우리의 논의를 바탕으로, 이러한 성능 차이를 설명할 수 있나요?**"]},{"cell_type":"markdown","metadata":{"id":"gMgP05xXUulG","colab_type":"text"},"source":["#### References\n","* James Bourbeau. *Supervised machine learning in Python \n","with scikit-learn*. URL: https://jrbourbeau.github.io/madpy-ml-sklearn-2018/#/\n","* Joaquin Vanschoren. *Machine Learning with Scikit-Learn*. URL: http://joaquinvanschoren.github.io/ML-course-R/TutorialSKlearn.slides.html#/\n","* User Guide - scikit-learn. URL: https://scikit-learn.org/stable/user_guide.html"]}]}